{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d4c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from nemo_microservices import NeMoMicroservices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03bd8ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"]=\"e0dae5c27937567b0d7c792082d063b2d7f7eed6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fe6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0b8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "# Initialize NeMo Microservices SDK client\n",
    "nemo_client = NeMoMicroservices(\n",
    "    base_url=NEMO_URL,\n",
    "    inference_base_url=NIM_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5ae4def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncDefaultPagination[Project](object='list', data=[], sort='created_at', pagination=DefaultPaginationPagination(current_page_size=0, page=1, page_size=10, total_pages=0, total_results=0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nemo_client.projects.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4cd9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store endpoint: http://data-store.test\n",
      "Entity Store, Customizer, Evaluator endpoint: http://nemo.test\n",
      "NIM endpoint: http://nim.test\n",
      "Namespace: lora-tutorial-ns\n",
      "Base Model for Customization: meta/llama-3.2-1b-instruct@v1.0.0+A100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data Store endpoint: {NDS_URL}\")\n",
    "print(f\"Entity Store, Customizer, Evaluator endpoint: {NEMO_URL}\")\n",
    "print(f\"NIM endpoint: {NIM_URL}\")\n",
    "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
    "print(f\"Base Model for Customization: {BASE_MODEL}@{BASE_MODEL_VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "275d979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where data preparation notebook saved finetuning and evaluation data\n",
    "DATA_ROOT = os.path.join(os.getcwd(), \"data\")\n",
    "# CUSTOMIZATION_DATA_ROOT = os.path.join(DATA_ROOT, \"customization\")\n",
    "# VALIDATION_DATA_ROOT = os.path.join(DATA_ROOT, \"validation\")\n",
    "# EVALUATION_DATA_ROOT = os.path.join(DATA_ROOT, \"evaluation\")\n",
    "\n",
    "# Sanity checks\n",
    "train_fp = f\"{DATA_ROOT}/training.jsonl\"\n",
    "assert os.path.exists(train_fp), f\"The training data at '{train_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "val_fp = f\"{DATA_ROOT}/validation.jsonl\"\n",
    "assert os.path.exists(val_fp), f\"The validation data at '{val_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "test_fp = f\"{DATA_ROOT}/test.jsonl\"\n",
    "assert os.path.exists(test_fp), f\"The test data at '{test_fp}' does not exist. Please ensure that the data was prepared successfully.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a375bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_namespaces(nemo_client, ds_host, namespace):\n",
    "    # Create namespace in Entity Store\n",
    "    try:\n",
    "        namespace_obj = nemo_client.namespaces.create(id=namespace)\n",
    "        print(f\"Created namespace in Entity Store: {namespace_obj.id}\")\n",
    "    except Exception as e:\n",
    "        # Handle if namespace already exists\n",
    "        if \"409\" in str(e) or \"422\" in str(e):\n",
    "            print(f\"Namespace {namespace} already exists in Entity Store\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # Create namespace in Data Store (still using requests as SDK doesn't cover Data Store)\n",
    "    nds_url = f\"{ds_host}/v1/datastore/namespaces\"\n",
    "    resp = requests.post(nds_url, data={\"namespace\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Data Store during namespace creation: {resp.status_code}\"\n",
    "    print(f\"Data Store namespace creation response: {resp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b715021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace lora-tutorial-ns already exists in Entity Store\n",
      "Data Store namespace creation response: <Response [409]>\n"
     ]
    }
   ],
   "source": [
    "create_namespaces(nemo_client=nemo_client, ds_host=NDS_URL, namespace=NMS_NAMESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a1b02f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store - Status Code: 201\n",
      "Response JSON: {'namespace': 'lora-tutorial-ns', 'created_at': '2025-08-13T14:28:28Z', 'updated_at': '2025-08-13T14:33:28Z'}\n",
      "\n",
      "Entity Store - Namespace: lora-tutorial-ns\n",
      "Created at: 2025-08-13 14:28:28.058716\n",
      "Description: None\n",
      "Project: None\n"
     ]
    }
   ],
   "source": [
    " # Verify Namespace in Data Store (using requests as SDK doesn't cover Data Store)\n",
    "response = requests.get(f\"{NDS_URL}/v1/datastore/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Data Store - Status Code: {response.status_code}\\nResponse JSON: {response.json()}\")\n",
    "\n",
    "# Verify Namespace in Entity Store\n",
    "namespace_obj = nemo_client.namespaces.retrieve(namespace_id=NMS_NAMESPACE)\n",
    "print(f\"\\nEntity Store - Namespace: {namespace_obj.id}\")\n",
    "print(f\"Created at: {namespace_obj.created_at}\")\n",
    "print(f\"Description: {namespace_obj.description}\")\n",
    "print(f\"Project: {namespace_obj.project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08285af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(id='lora-tutorial-ns', created_at=datetime.datetime(2025, 8, 13, 14, 28, 28, 58716), custom_fields={}, description=None, ownership=None, project=None, updated_at=datetime.datetime(2025, 8, 13, 14, 28, 28, 58719))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namespace_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e42b9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ffe235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "409 Client Error: Conflict for url: http://data-store.test/v1/hf/api/repos/create\n\nYou already created this repo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/requests/models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 409 Client Error: Conflict for url: http://data-store.test/v1/hf/api/repos/create",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m hf_api \u001b[38;5;241m=\u001b[39m HfApi(endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNDS_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/v1/hf\u001b[39m\u001b[38;5;124m\"\u001b[39m, token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create repo\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mhf_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3755\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3752\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   3754\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3755\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3756\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[1;32m   3758\u001b[0m         \u001b[38;5;66;03m# Repo already exists and `exist_ok=True`\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:482\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 409 Client Error: Conflict for url: http://data-store.test/v1/hf/api/repos/create\n\nYou already created this repo"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "hf_api = HfApi(endpoint=f\"{NDS_URL}/v1/hf\", token=\"\")\n",
    "\n",
    "# Create repo\n",
    "hf_api.create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "830a69d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='', commit_message='Upload testing/test.jsonl with huggingface_hub', commit_description='', oid='a94c9b8bcf70efc7cf80c008a3c033450d2a246a', pr_url=None, repo_url=RepoUrl('', endpoint='https://huggingface.co', repo_type='model', repo_id=''), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api.upload_file(path_or_fileobj=train_fp,\n",
    "    path_in_repo=\"training/train.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(path_or_fileobj=val_fp,\n",
    "    path_in_repo=\"validation/val.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(path_or_fileobj=test_fp,\n",
    "    path_in_repo=\"testing/test.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e461a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResponse(id='dataset-2ibXH5f1wRC1jzn1ws9sQu', deleted_at=None, message='Resource deleted successfully.')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nemo_client.datasets.delete(dataset_name=DATASET_NAME, namespace=NMS_NAMESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dad47ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset: lora-tutorial-ns/news-lora-dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(files_url='hf://datasets/lora-tutorial-ns/news-lora-dataset', id='dataset-MvfFbbDRxmLWS8nmc7WGMX', created_at=datetime.datetime(2025, 8, 13, 16, 41, 25, 865354), custom_fields={}, description='News Dataset for FSI Blueprint', format=None, hf_endpoint=None, limit=None, name='news-lora-dataset', namespace='lora-tutorial-ns', project='tool_calling', split=None, updated_at=datetime.datetime(2025, 8, 13, 16, 41, 25, 865357))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Create dataset\n",
    "dataset = nemo_client.datasets.create(\n",
    "    name=DATASET_NAME,\n",
    "    namespace=NMS_NAMESPACE,\n",
    "    description=\"News Dataset for FSI Blueprint\",\n",
    "    files_url=f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}\",\n",
    "    project=\"tool_calling\",\n",
    "    \n",
    ")\n",
    "print(f\"Created dataset: {dataset.namespace}/{dataset.name}\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "674705b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files URL: hf://datasets/lora-tutorial-ns/news-lora-dataset\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to validate dataset\n",
    "dataset_obj = nemo_client.datasets.retrieve(namespace=NMS_NAMESPACE, dataset_name=DATASET_NAME)\n",
    "\n",
    "print(\"Files URL:\", dataset_obj.files_url)\n",
    "assert dataset_obj.files_url == f\"hf://datasets/{repo_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f93578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta/llama-3.2-1b-instruct@v1.0.0+A100'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{BASE_MODEL}@{BASE_MODEL_VERSION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfcb4d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 configs\n",
      "Namespace: meta Config:llama-3.2-1b-instruct@v1.0.0+L40 - None\n",
      "Namespace: meta Config:llama-3.2-1b-instruct@v1.0.0+A100 - None\n"
     ]
    }
   ],
   "source": [
    "# List customization configs with filters\n",
    "configs = nemo_client.customization.configs.list(\n",
    "    page=1,\n",
    "    page_size=10,\n",
    "    sort=\"-created_at\",\n",
    "    filter={\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"enabled\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Found {len(configs.data)} configs\")\n",
    "for config in configs.data:\n",
    "    print(f\"Namespace: {config.namespace} Config:{config.name} - {config.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fa0be350",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL = 'lora-tutorial-ns/llama-3.2-1b-xlam-run1@v5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResponse(id='model-YUsHWp4sVSgpEBKzmW64JJ', deleted_at=None, message='Resource deleted successfully.')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nemo_client.models.delete(namespace= NMS_NAMESPACE,model_name='llama-3.2-1b-xlam-run1@v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "10099b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created customization job: cust-VJ7FRPk9FLuH6RyMLYDyMb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomizationJob(config='meta/llama-3.2-1b-instruct@v1.0.0+A100', dataset='lora-tutorial-ns/news-lora-dataset', hyperparameters=Hyperparameters(finetuning_type='lora', batch_size=16, distillation=None, dpo=None, epochs=2, learning_rate=0.0001, log_every_n_steps=None, lora=LoraParameters(adapter_dim=16, adapter_dropout=0.1, alpha=16, target_modules=None), sequence_packing_enabled=True, sft=None, training_type='sft', val_check_interval=None, weight_decay=None), id='cust-VJ7FRPk9FLuH6RyMLYDyMb', config_snapshot=CustomizationConfigJobValue(base_model='meta/llama-3.2-1b-instruct', max_seq_length=4096, precision='bf16-mixed', training_option=CustomizationTrainingOption(finetuning_type='lora', micro_batch_size=1, num_gpus=1, training_type='sft', data_parallel_size=1, num_nodes=1, pipeline_parallel_size=1, tensor_parallel_size=1, use_sequence_parallel=False), dataset_schema=None, prompt_template='{prompt} {completion}'), created_at=datetime.datetime(2025, 8, 13, 18, 17, 19, 29071), dataset_parameters=None, description=None, integrations=None, namespace='default', output_model='lora-tutorial-ns/llama-3.2-1b-xlam-run1@v5', ownership=None, project=None, status='created', status_details=CustomizationStatusDetails(created_at=datetime.datetime(2025, 8, 13, 18, 17, 19, 419953), status=None, updated_at=datetime.datetime(2025, 8, 13, 18, 17, 19, 419953), best_epoch=None, elapsed_time=0.0, epochs_completed=0, metrics=None, percentage_done=0.0, status_logs=[StatusLog(updated_at=datetime.datetime(2025, 8, 13, 18, 17, 19, 419953), detail=None, message='created')], steps_completed=0, steps_per_epoch=None, train_loss=None, val_loss=None), updated_at=datetime.datetime(2025, 8, 13, 18, 17, 19, 29074), warnings=None)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create customization job\n",
    "# If WANDB_API_KEY is set, we send it in the request header, which will report the training metrics to Weights & Biases (WandB).\n",
    "if WANDB_API_KEY:\n",
    "    client_with_wandb = nemo_client.with_options(default_headers={\"wandb-api-key\": WANDB_API_KEY})\n",
    "else:\n",
    "    client_with_wandb = nemo_client\n",
    "\n",
    "customization = client_with_wandb.customization.jobs.create(\n",
    "    name=\"llama-3.2-1b-xlam-ft-seq-packed\",\n",
    "    output_model=CUSTOM_MODEL,\n",
    "    config=f\"{BASE_MODEL}@{BASE_MODEL_VERSION}\",\n",
    "    dataset={\"name\": DATASET_NAME, \"namespace\": NMS_NAMESPACE},\n",
    "    \n",
    "    hyperparameters={\n",
    "        \"sequence_packing_enabled\": True,\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"epochs\": 2,\n",
    "        \"batch_size\": 16,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"lora\": {\n",
    "            \"adapter_dim\": 16,\n",
    "            \"adapter_dropout\": 0.1\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Created customization job: {customization.id}\")\n",
    "customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1b99a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To track status\n",
    "JOB_ID = customization.id\n",
    "\n",
    "customization = nemo_client.customization.jobs.retrieve(JOB_ID)\n",
    "\n",
    "# This will be the name of the model that will be used to send inference queries to\n",
    "CUSTOMIZED_MODEL = customization.output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8608c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nemo_client.customization.jobs.cancel(job_id=JOB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b012883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage done: 0.0\n",
      "Job Status: {\n",
      "  \"created_at\": \"2025-08-13 18:17:19.419953\",\n",
      "  \"status\": \"created\",\n",
      "  \"updated_at\": \"2025-08-13 18:17:19.419953\",\n",
      "  \"best_epoch\": null,\n",
      "  \"elapsed_time\": 0.0,\n",
      "  \"epochs_completed\": 0,\n",
      "  \"metrics\": null,\n",
      "  \"percentage_done\": 0.0,\n",
      "  \"status_logs\": [\n",
      "    {\n",
      "      \"updated_at\": \"2025-08-13 18:17:19.419953\",\n",
      "      \"detail\": null,\n",
      "      \"message\": \"created\"\n",
      "    }\n",
      "  ],\n",
      "  \"steps_completed\": 0,\n",
      "  \"steps_per_epoch\": null,\n",
      "  \"train_loss\": null,\n",
      "  \"val_loss\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    " # Get job status\n",
    "job_status = nemo_client.customization.jobs.status(job_id=JOB_ID)\n",
    "\n",
    "print(\"Percentage done:\", job_status.percentage_done)\n",
    "print(\"Job Status:\", json.dumps(job_status.model_dump(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f2e55ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: running after 5.49 seconds. Progress: 100.0%\n",
      "Job status: completed after 10.55 seconds. Progress: 100%\n"
     ]
    }
   ],
   "source": [
    " # Add wait job function to wait for the customization job to complete\n",
    "\n",
    "from time import sleep, time\n",
    "\n",
    "def wait_job(nemo_client, job_id: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    \"\"\"Helper for waiting an eval job using SDK.\"\"\"\n",
    "    start_time = time()\n",
    "    job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "    status = job.status\n",
    "\n",
    "    while (status in [\"pending\", \"created\", \"running\"]):\n",
    "        # Check for timeout\n",
    "        if time() - start_time > timeout:\n",
    "            raise RuntimeError(f\"Took more than {timeout} seconds.\")\n",
    "\n",
    "        # Sleep before polling again\n",
    "        sleep(polling_interval)\n",
    "\n",
    "        # Fetch updated status and progress\n",
    "        job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "        status = job.status\n",
    "        progress = 0.0\n",
    "        if status == \"running\" and job.status_details:\n",
    "            progress = job.status_details.percentage_done or 0.0\n",
    "        elif status == \"completed\":\n",
    "            progress = 100\n",
    "\n",
    "        print(f\"Job status: {status} after {time() - start_time:.2f} seconds. Progress: {progress}%\")\n",
    "\n",
    "\n",
    "    return job\n",
    "\n",
    "job = wait_job(nemo_client, JOB_ID, polling_interval=5, timeout=2400)\n",
    "\n",
    "# Wait for 2 minutes, because sometimes, the job is finished, but the finetuned model is not ready in NIM yet.\n",
    "sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "829fec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 models in namespace lora-tutorial-ns:\n",
      "\n",
      "Model: llama-3.2-1b-xlam-run1@v5\n",
      "  Namespace: lora-tutorial-ns\n",
      "  Base Model: meta/llama-3.2-1b-instruct\n",
      "  Created: 2025-08-13 18:17:19.448554\n",
      "  Fine-tuning Type: lora\n",
      "\n",
      "Model: llama-3.2-1b-xlam-run1@v4\n",
      "  Namespace: lora-tutorial-ns\n",
      "  Base Model: meta/llama-3.2-1b-instruct\n",
      "  Created: 2025-08-13 17:02:36.340413\n",
      "  Fine-tuning Type: lora\n",
      "\n",
      "Model: llama-3.2-1b-xlam-run1@v1\n",
      "  Namespace: lora-tutorial-ns\n",
      "  Base Model: meta/llama-3.2-1b-instruct\n",
      "  Created: 2025-08-13 14:33:29.640105\n",
      "  Fine-tuning Type: lora\n"
     ]
    }
   ],
   "source": [
    " # List models with filters\n",
    "models_page = nemo_client.models.list(\n",
    "    filter={\"namespace\": NMS_NAMESPACE},\n",
    "    sort=\"-created_at\"\n",
    ")\n",
    "\n",
    "# Print models information\n",
    "print(f\"Found {len(models_page.data)} models in namespace {NMS_NAMESPACE}:\")\n",
    "for model in models_page.data:\n",
    "    print(f\"\\nModel: {model.name}\")\n",
    "    print(f\"  Namespace: {model.namespace}\")\n",
    "    print(f\"  Base Model: {model.base_model}\")\n",
    "    print(f\"  Created: {model.created_at}\")\n",
    "    if model.peft:\n",
    "        print(f\"  Fine-tuning Type: {model.peft.finetuning_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b6f8f779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: lora-tutorial-ns/llama-3.2-1b-xlam-run1@v5\n",
      "Base Model: meta/llama-3.2-1b-instruct\n",
      "Status: upload_completed\n"
     ]
    }
   ],
   "source": [
    "# CUSTOMIZED_MODEL is constructed as `namespace/model_name`, so we need to extract the model name\n",
    "model = nemo_client.models.retrieve(namespace=NMS_NAMESPACE, model_name=CUSTOMIZED_MODEL.split(\"/\")[1])\n",
    "\n",
    "print(f\"Model: {model.namespace}/{model.name}\")\n",
    "print(f\"Base Model: {model.base_model}\")\n",
    "print(f\"Status: {model.artifact.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "32ac0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Check if the custom LoRA model is hosted by NVIDIA NIM\n",
    "models = nemo_client.inference.models.list()\n",
    "model_names = [model.id for model in models.data]\n",
    "\n",
    "assert CUSTOMIZED_MODEL in model_names, \\\n",
    "    f\"Model {CUSTOMIZED_MODEL} not found\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "693b9b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7676 examples in the test set\n"
     ]
    }
   ],
   "source": [
    "def read_jsonl(file_path):\n",
    "    \"\"\"Reads a JSON Lines file and yields parsed JSON objects\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "test_data = list(read_jsonl(test_fp))\n",
    "\n",
    "print(f\"There are {len(test_data)} examples in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a1fbc147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 77 batches\n",
      "First batch has 100 messages\n",
      "Sample message from first batch: {'role': 'user', 'content': \"Given the following headline:\\n### START HEADLINE ###\\n\\nHearing Endo Int'l Held Talks to Sell Paladin Labs to Knight Therapeutics\\n\\n### END HEADLINE ###\\n\\nWhat event type best classifies it? Choose from the following list:\\n\\n-analyst rating\\n-price targets\\n-earnings\\n-labour related\\n-mergers and acquisitions\\n-dividends\\n-regulatory\\n-stock price movement\\n-credit ratings\\n-products-services\\n-product approval\\n-guidance\\n-other\\n\\nProvide only the event type putting it inside double square brackets and in a new line like:\\n[[label]]\\n\\n### START EVENT OUTPUT ###\\n\\n\"}\n"
     ]
    }
   ],
   "source": [
    "def create_message_batches(data_list, batch_size=100):\n",
    "    \"\"\"\n",
    "    Creates batches of messages from a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        data_list: List of dictionaries containing 'prompt' key\n",
    "        batch_size: Size of each batch (default: 100)\n",
    "    \n",
    "    Returns:\n",
    "        List of batches, where each batch contains message dictionaries\n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    \n",
    "    for i in range(0, len(data_list), batch_size):\n",
    "        batch = data_list[i:i + batch_size]\n",
    "        \n",
    "        # Create messages for this batch\n",
    "        batch_messages = []\n",
    "        for test_sample in batch:\n",
    "            messages = {\"role\": \"user\", \"content\": test_sample['prompt']}\n",
    "            batch_messages.append(messages)\n",
    "        \n",
    "        batches.append(batch_messages)\n",
    "    \n",
    "    return batches\n",
    "\n",
    "# Usage example:\n",
    "message_batches = create_message_batches(test_data, batch_size=100)\n",
    "\n",
    "print(f\"Created {len(message_batches)} batches\")\n",
    "print(f\"First batch has {len(message_batches[0])} messages\")\n",
    "print(f\"Sample message from first batch: {message_batches[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d523f724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 messages\n",
      "Processed 1000 messages\n",
      "Processed 1500 messages\n",
      "Processed 2000 messages\n",
      "Processed 2500 messages\n",
      "Processed 3000 messages\n",
      "Processed 3500 messages\n",
      "Processed 4000 messages\n",
      "Processed 4500 messages\n",
      "Processed 5000 messages\n",
      "Processed 5500 messages\n",
      "Processed 6000 messages\n",
      "Processed 6500 messages\n",
      "Processed 7000 messages\n",
      "Processed 7500 messages\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "c=0\n",
    "for batch in message_batches:\n",
    "    for message in batch:\n",
    "        completion = nemo_client.chat.completions.create(model = CUSTOMIZED_MODEL,\n",
    "                                            messages = [message],\n",
    "                                            temperature = 0.1,\n",
    "                                            top_p = 0.7,\n",
    "                                            max_tokens = 512,\n",
    "                                            stream = False\n",
    "                                            )\n",
    "        resp = completion.choices[0].message.content\n",
    "        responses.append(resp)\n",
    "        c += 1\n",
    "        if c % 500 == 0:\n",
    "            print(f\"Processed {c} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "71268686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean responses using lambda to remove square brackets\n",
    "responses = list(map(lambda x: x.replace('[', '').replace(']', '').replace('-p','p').replace('-e','e'), responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4c80b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = list(map(lambda x: x.lower(), responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2ccfa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [i['completion'] for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "da742a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyst rating',\n",
       " 'credit ratings',\n",
       " 'dividends',\n",
       " 'earnings',\n",
       " 'guidance',\n",
       " 'labour issues',\n",
       " 'mergers and acquisitions',\n",
       " 'no event',\n",
       " 'other',\n",
       " 'price targets',\n",
       " 'product approval',\n",
       " 'products-services',\n",
       " 'regulatory',\n",
       " 'stock price movement'}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a5c25844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyst rating',\n",
       " 'credit ratings',\n",
       " 'dividends',\n",
       " 'dividers',\n",
       " 'earnings',\n",
       " 'growth',\n",
       " 'guidance',\n",
       " 'label',\n",
       " 'labor issues',\n",
       " 'labour issues',\n",
       " 'labour related',\n",
       " 'mergers and acquisitions',\n",
       " 'other',\n",
       " 'price targets',\n",
       " 'product approval',\n",
       " 'products-services',\n",
       " 'regulatory',\n",
       " 'stock price movement'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ece775d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3f769509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyst rating': {'precision': 0.1497019715726731,\n",
       "  'recall': 0.7709563164108618,\n",
       "  'f1-score': 0.250719907851795,\n",
       "  'support': 847.0},\n",
       " 'credit ratings': {'precision': 0.6363636363636364,\n",
       "  'recall': 0.175,\n",
       "  'f1-score': 0.27450980392156865,\n",
       "  'support': 40.0},\n",
       " 'dividends': {'precision': 0.9591836734693877,\n",
       "  'recall': 0.8623853211009175,\n",
       "  'f1-score': 0.9082125603864735,\n",
       "  'support': 109.0},\n",
       " 'dividers': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'earnings': {'precision': 0.7695852534562212,\n",
       "  'recall': 0.334,\n",
       "  'f1-score': 0.46582984658298465,\n",
       "  'support': 1000.0},\n",
       " 'growth': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0},\n",
       " 'guidance': {'precision': 0.15777777777777777,\n",
       "  'recall': 0.2862903225806452,\n",
       "  'f1-score': 0.2034383954154728,\n",
       "  'support': 496.0},\n",
       " 'label': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0},\n",
       " 'labor issues': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'labour issues': {'precision': 0.1073558648111332,\n",
       "  'recall': 0.2967032967032967,\n",
       "  'f1-score': 0.15766423357664233,\n",
       "  'support': 182.0},\n",
       " 'labour related': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'mergers and acquisitions': {'precision': 0.9173553719008265,\n",
       "  'recall': 0.23870967741935484,\n",
       "  'f1-score': 0.378839590443686,\n",
       "  'support': 465.0},\n",
       " 'no event': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 438.0},\n",
       " 'other': {'precision': 0.17777777777777778,\n",
       "  'recall': 0.010062893081761006,\n",
       "  'f1-score': 0.01904761904761905,\n",
       "  'support': 795.0},\n",
       " 'price targets': {'precision': 0.42857142857142855,\n",
       "  'recall': 0.0030241935483870967,\n",
       "  'f1-score': 0.006006006006006006,\n",
       "  'support': 992.0},\n",
       " 'product approval': {'precision': 0.17647058823529413,\n",
       "  'recall': 0.03333333333333333,\n",
       "  'f1-score': 0.056074766355140186,\n",
       "  'support': 90.0},\n",
       " 'products-services': {'precision': 0.6,\n",
       "  'recall': 0.037209302325581395,\n",
       "  'f1-score': 0.07007299270072993,\n",
       "  'support': 645.0},\n",
       " 'regulatory': {'precision': 0.3677581863979849,\n",
       "  'recall': 0.3310657596371882,\n",
       "  'f1-score': 0.34844868735083534,\n",
       "  'support': 441.0},\n",
       " 'stock price movement': {'precision': 0.5671296296296297,\n",
       "  'recall': 0.21566901408450703,\n",
       "  'f1-score': 0.3125,\n",
       "  'support': 1136.0},\n",
       " 'accuracy': 0.2376237623762376,\n",
       " 'macro avg': {'precision': 0.31658058736651423,\n",
       "  'recall': 0.18917944369609654,\n",
       "  'f1-score': 0.18165075840205017,\n",
       "  'support': 7676.0},\n",
       " 'weighted avg': {'precision': 0.4333708109987506,\n",
       "  'recall': 0.2376237623762376,\n",
       "  'f1-score': 0.2180740502152485,\n",
       "  'support': 7676.0}}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_true=true_labels,\n",
    "    y_pred=responses,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8823c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of your custom model is: lora-tutorial-ns/llama-3.2-1b-xlam-run1@v5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name of your custom model is: {CUSTOMIZED_MODEL}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef763cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
