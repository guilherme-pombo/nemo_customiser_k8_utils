{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d4c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from nemo_microservices import NeMoMicroservices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dad47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "# Initialize NeMo Microservices SDK client\n",
    "nemo_client = NeMoMicroservices(\n",
    "    base_url=NEMO_URL,\n",
    "    inference_base_url=NIM_URL,\n",
    ")\n",
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfcb4d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 configs\n",
      "Namespace: meta Config:llama-3.2-1b-instruct@v1.0.0+L40 - None\n",
      "Namespace: meta Config:llama-3.2-1b-instruct@v1.0.0+A100 - None\n"
     ]
    }
   ],
   "source": [
    "# List customization configs with filters\n",
    "configs = nemo_client.customization.configs.list(\n",
    "    page=1,\n",
    "    page_size=10,\n",
    "    sort=\"-created_at\",\n",
    "    filter={\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"enabled\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Found {len(configs.data)} configs\")\n",
    "for config in configs.data:\n",
    "    print(f\"Namespace: {config.namespace} Config:{config.name} - {config.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fa0be350",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL = 'lora-tutorial-ns/llama-3.2-1b-xlam-run1@v5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResponse(id='model-YUsHWp4sVSgpEBKzmW64JJ', deleted_at=None, message='Resource deleted successfully.')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nemo_client.models.delete(namespace= NMS_NAMESPACE,model_name='llama-3.2-1b-xlam-run1@v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "10099b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created customization job: cust-VJ7FRPk9FLuH6RyMLYDyMb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomizationJob(config='meta/llama-3.2-1b-instruct@v1.0.0+A100', dataset='lora-tutorial-ns/news-lora-dataset', hyperparameters=Hyperparameters(finetuning_type='lora', batch_size=16, distillation=None, dpo=None, epochs=2, learning_rate=0.0001, log_every_n_steps=None, lora=LoraParameters(adapter_dim=16, adapter_dropout=0.1, alpha=16, target_modules=None), sequence_packing_enabled=True, sft=None, training_type='sft', val_check_interval=None, weight_decay=None), id='cust-VJ7FRPk9FLuH6RyMLYDyMb', config_snapshot=CustomizationConfigJobValue(base_model='meta/llama-3.2-1b-instruct', max_seq_length=4096, precision='bf16-mixed', training_option=CustomizationTrainingOption(finetuning_type='lora', micro_batch_size=1, num_gpus=1, training_type='sft', data_parallel_size=1, num_nodes=1, pipeline_parallel_size=1, tensor_parallel_size=1, use_sequence_parallel=False), dataset_schema=None, prompt_template='{prompt} {completion}'), created_at=datetime.datetime(2025, 8, 13, 18, 17, 19, 29071), dataset_parameters=None, description=None, integrations=None, namespace='default', output_model='lora-tutorial-ns/llama-3.2-1b-xlam-run1@v5', ownership=None, project=None, status='created', status_details=CustomizationStatusDetails(created_at=datetime.datetime(2025, 8, 13, 18, 17, 19, 419953), status=None, updated_at=datetime.datetime(2025, 8, 13, 18, 17, 19, 419953), best_epoch=None, elapsed_time=0.0, epochs_completed=0, metrics=None, percentage_done=0.0, status_logs=[StatusLog(updated_at=datetime.datetime(2025, 8, 13, 18, 17, 19, 419953), detail=None, message='created')], steps_completed=0, steps_per_epoch=None, train_loss=None, val_loss=None), updated_at=datetime.datetime(2025, 8, 13, 18, 17, 19, 29074), warnings=None)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create customization job\n",
    "# If WANDB_API_KEY is set, we send it in the request header, which will report the training metrics to Weights & Biases (WandB).\n",
    "if WANDB_API_KEY:\n",
    "    client_with_wandb = nemo_client.with_options(default_headers={\"wandb-api-key\": WANDB_API_KEY})\n",
    "else:\n",
    "    client_with_wandb = nemo_client\n",
    "\n",
    "customization = client_with_wandb.customization.jobs.create(\n",
    "    name=\"llama-3.2-1b-xlam-ft-seq-packed\",\n",
    "    output_model=CUSTOM_MODEL,\n",
    "    config=f\"{BASE_MODEL}@{BASE_MODEL_VERSION}\",\n",
    "    dataset={\"name\": DATASET_NAME, \"namespace\": NMS_NAMESPACE},\n",
    "    \n",
    "    hyperparameters={\n",
    "        \"sequence_packing_enabled\": True,\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"epochs\": 2,\n",
    "        \"batch_size\": 16,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"lora\": {\n",
    "            \"adapter_dim\": 16,\n",
    "            \"adapter_dropout\": 0.1\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Created customization job: {customization.id}\")\n",
    "customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1b99a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To track status\n",
    "JOB_ID = customization.id\n",
    "\n",
    "customization = nemo_client.customization.jobs.retrieve(JOB_ID)\n",
    "\n",
    "# This will be the name of the model that will be used to send inference queries to\n",
    "CUSTOMIZED_MODEL = customization.output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8608c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nemo_client.customization.jobs.cancel(job_id=JOB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b012883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage done: 0.0\n",
      "Job Status: {\n",
      "  \"created_at\": \"2025-08-13 18:17:19.419953\",\n",
      "  \"status\": \"created\",\n",
      "  \"updated_at\": \"2025-08-13 18:17:19.419953\",\n",
      "  \"best_epoch\": null,\n",
      "  \"elapsed_time\": 0.0,\n",
      "  \"epochs_completed\": 0,\n",
      "  \"metrics\": null,\n",
      "  \"percentage_done\": 0.0,\n",
      "  \"status_logs\": [\n",
      "    {\n",
      "      \"updated_at\": \"2025-08-13 18:17:19.419953\",\n",
      "      \"detail\": null,\n",
      "      \"message\": \"created\"\n",
      "    }\n",
      "  ],\n",
      "  \"steps_completed\": 0,\n",
      "  \"steps_per_epoch\": null,\n",
      "  \"train_loss\": null,\n",
      "  \"val_loss\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    " # Get job status\n",
    "job_status = nemo_client.customization.jobs.status(job_id=JOB_ID)\n",
    "\n",
    "print(\"Percentage done:\", job_status.percentage_done)\n",
    "print(\"Job Status:\", json.dumps(job_status.model_dump(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f2e55ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: running after 5.49 seconds. Progress: 100.0%\n",
      "Job status: completed after 10.55 seconds. Progress: 100%\n"
     ]
    }
   ],
   "source": [
    " # Add wait job function to wait for the customization job to complete\n",
    "\n",
    "from time import sleep, time\n",
    "\n",
    "def wait_job(nemo_client, job_id: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    \"\"\"Helper for waiting an eval job using SDK.\"\"\"\n",
    "    start_time = time()\n",
    "    job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "    status = job.status\n",
    "\n",
    "    while (status in [\"pending\", \"created\", \"running\"]):\n",
    "        # Check for timeout\n",
    "        if time() - start_time > timeout:\n",
    "            raise RuntimeError(f\"Took more than {timeout} seconds.\")\n",
    "\n",
    "        # Sleep before polling again\n",
    "        sleep(polling_interval)\n",
    "\n",
    "        # Fetch updated status and progress\n",
    "        job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "        status = job.status\n",
    "        progress = 0.0\n",
    "        if status == \"running\" and job.status_details:\n",
    "            progress = job.status_details.percentage_done or 0.0\n",
    "        elif status == \"completed\":\n",
    "            progress = 100\n",
    "\n",
    "        print(f\"Job status: {status} after {time() - start_time:.2f} seconds. Progress: {progress}%\")\n",
    "\n",
    "\n",
    "    return job\n",
    "\n",
    "job = wait_job(nemo_client, JOB_ID, polling_interval=5, timeout=2400)\n",
    "\n",
    "# Wait for 2 minutes, because sometimes, the job is finished, but the finetuned model is not ready in NIM yet.\n",
    "sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "829fec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 models in namespace lora-tutorial-ns:\n",
      "\n",
      "Model: llama-3.2-1b-xlam-run1@v5\n",
      "  Namespace: lora-tutorial-ns\n",
      "  Base Model: meta/llama-3.2-1b-instruct\n",
      "  Created: 2025-08-13 18:17:19.448554\n",
      "  Fine-tuning Type: lora\n",
      "\n",
      "Model: llama-3.2-1b-xlam-run1@v4\n",
      "  Namespace: lora-tutorial-ns\n",
      "  Base Model: meta/llama-3.2-1b-instruct\n",
      "  Created: 2025-08-13 17:02:36.340413\n",
      "  Fine-tuning Type: lora\n",
      "\n",
      "Model: llama-3.2-1b-xlam-run1@v1\n",
      "  Namespace: lora-tutorial-ns\n",
      "  Base Model: meta/llama-3.2-1b-instruct\n",
      "  Created: 2025-08-13 14:33:29.640105\n",
      "  Fine-tuning Type: lora\n"
     ]
    }
   ],
   "source": [
    " # List models with filters\n",
    "models_page = nemo_client.models.list(\n",
    "    filter={\"namespace\": NMS_NAMESPACE},\n",
    "    sort=\"-created_at\"\n",
    ")\n",
    "\n",
    "# Print models information\n",
    "print(f\"Found {len(models_page.data)} models in namespace {NMS_NAMESPACE}:\")\n",
    "for model in models_page.data:\n",
    "    print(f\"\\nModel: {model.name}\")\n",
    "    print(f\"  Namespace: {model.namespace}\")\n",
    "    print(f\"  Base Model: {model.base_model}\")\n",
    "    print(f\"  Created: {model.created_at}\")\n",
    "    if model.peft:\n",
    "        print(f\"  Fine-tuning Type: {model.peft.finetuning_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b6f8f779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: lora-tutorial-ns/llama-3.2-1b-xlam-run1@v5\n",
      "Base Model: meta/llama-3.2-1b-instruct\n",
      "Status: upload_completed\n"
     ]
    }
   ],
   "source": [
    "# CUSTOMIZED_MODEL is constructed as `namespace/model_name`, so we need to extract the model name\n",
    "model = nemo_client.models.retrieve(namespace=NMS_NAMESPACE, model_name=CUSTOMIZED_MODEL.split(\"/\")[1])\n",
    "\n",
    "print(f\"Model: {model.namespace}/{model.name}\")\n",
    "print(f\"Base Model: {model.base_model}\")\n",
    "print(f\"Status: {model.artifact.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "32ac0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Check if the custom LoRA model is hosted by NVIDIA NIM\n",
    "models = nemo_client.inference.models.list()\n",
    "model_names = [model.id for model in models.data]\n",
    "\n",
    "assert CUSTOMIZED_MODEL in model_names, \\\n",
    "    f\"Model {CUSTOMIZED_MODEL} not found\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "693b9b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7676 examples in the test set\n"
     ]
    }
   ],
   "source": [
    "def read_jsonl(file_path):\n",
    "    \"\"\"Reads a JSON Lines file and yields parsed JSON objects\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "test_data = list(read_jsonl(test_fp))\n",
    "\n",
    "print(f\"There are {len(test_data)} examples in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a1fbc147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 77 batches\n",
      "First batch has 100 messages\n",
      "Sample message from first batch: {'role': 'user', 'content': \"Given the following headline:\\n### START HEADLINE ###\\n\\nHearing Endo Int'l Held Talks to Sell Paladin Labs to Knight Therapeutics\\n\\n### END HEADLINE ###\\n\\nWhat event type best classifies it? Choose from the following list:\\n\\n-analyst rating\\n-price targets\\n-earnings\\n-labour related\\n-mergers and acquisitions\\n-dividends\\n-regulatory\\n-stock price movement\\n-credit ratings\\n-products-services\\n-product approval\\n-guidance\\n-other\\n\\nProvide only the event type putting it inside double square brackets and in a new line like:\\n[[label]]\\n\\n### START EVENT OUTPUT ###\\n\\n\"}\n"
     ]
    }
   ],
   "source": [
    "def create_message_batches(data_list, batch_size=100):\n",
    "    \"\"\"\n",
    "    Creates batches of messages from a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        data_list: List of dictionaries containing 'prompt' key\n",
    "        batch_size: Size of each batch (default: 100)\n",
    "    \n",
    "    Returns:\n",
    "        List of batches, where each batch contains message dictionaries\n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    \n",
    "    for i in range(0, len(data_list), batch_size):\n",
    "        batch = data_list[i:i + batch_size]\n",
    "        \n",
    "        # Create messages for this batch\n",
    "        batch_messages = []\n",
    "        for test_sample in batch:\n",
    "            messages = {\"role\": \"user\", \"content\": test_sample['prompt']}\n",
    "            batch_messages.append(messages)\n",
    "        \n",
    "        batches.append(batch_messages)\n",
    "    \n",
    "    return batches\n",
    "\n",
    "# Usage example:\n",
    "message_batches = create_message_batches(test_data, batch_size=100)\n",
    "\n",
    "print(f\"Created {len(message_batches)} batches\")\n",
    "print(f\"First batch has {len(message_batches[0])} messages\")\n",
    "print(f\"Sample message from first batch: {message_batches[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d523f724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 messages\n",
      "Processed 1000 messages\n",
      "Processed 1500 messages\n",
      "Processed 2000 messages\n",
      "Processed 2500 messages\n",
      "Processed 3000 messages\n",
      "Processed 3500 messages\n",
      "Processed 4000 messages\n",
      "Processed 4500 messages\n",
      "Processed 5000 messages\n",
      "Processed 5500 messages\n",
      "Processed 6000 messages\n",
      "Processed 6500 messages\n",
      "Processed 7000 messages\n",
      "Processed 7500 messages\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "c=0\n",
    "for batch in message_batches:\n",
    "    for message in batch:\n",
    "        completion = nemo_client.chat.completions.create(model = CUSTOMIZED_MODEL,\n",
    "                                            messages = [message],\n",
    "                                            temperature = 0.1,\n",
    "                                            top_p = 0.7,\n",
    "                                            max_tokens = 512,\n",
    "                                            stream = False\n",
    "                                            )\n",
    "        resp = completion.choices[0].message.content\n",
    "        responses.append(resp)\n",
    "        c += 1\n",
    "        if c % 500 == 0:\n",
    "            print(f\"Processed {c} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "71268686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean responses using lambda to remove square brackets\n",
    "responses = list(map(lambda x: x.replace('[', '').replace(']', '').replace('-p','p').replace('-e','e'), responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4c80b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = list(map(lambda x: x.lower(), responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2ccfa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [i['completion'] for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "da742a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyst rating',\n",
       " 'credit ratings',\n",
       " 'dividends',\n",
       " 'earnings',\n",
       " 'guidance',\n",
       " 'labour issues',\n",
       " 'mergers and acquisitions',\n",
       " 'no event',\n",
       " 'other',\n",
       " 'price targets',\n",
       " 'product approval',\n",
       " 'products-services',\n",
       " 'regulatory',\n",
       " 'stock price movement'}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a5c25844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyst rating',\n",
       " 'credit ratings',\n",
       " 'dividends',\n",
       " 'dividers',\n",
       " 'earnings',\n",
       " 'growth',\n",
       " 'guidance',\n",
       " 'label',\n",
       " 'labor issues',\n",
       " 'labour issues',\n",
       " 'labour related',\n",
       " 'mergers and acquisitions',\n",
       " 'other',\n",
       " 'price targets',\n",
       " 'product approval',\n",
       " 'products-services',\n",
       " 'regulatory',\n",
       " 'stock price movement'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ece775d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3f769509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyst rating': {'precision': 0.1497019715726731,\n",
       "  'recall': 0.7709563164108618,\n",
       "  'f1-score': 0.250719907851795,\n",
       "  'support': 847.0},\n",
       " 'credit ratings': {'precision': 0.6363636363636364,\n",
       "  'recall': 0.175,\n",
       "  'f1-score': 0.27450980392156865,\n",
       "  'support': 40.0},\n",
       " 'dividends': {'precision': 0.9591836734693877,\n",
       "  'recall': 0.8623853211009175,\n",
       "  'f1-score': 0.9082125603864735,\n",
       "  'support': 109.0},\n",
       " 'dividers': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'earnings': {'precision': 0.7695852534562212,\n",
       "  'recall': 0.334,\n",
       "  'f1-score': 0.46582984658298465,\n",
       "  'support': 1000.0},\n",
       " 'growth': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0},\n",
       " 'guidance': {'precision': 0.15777777777777777,\n",
       "  'recall': 0.2862903225806452,\n",
       "  'f1-score': 0.2034383954154728,\n",
       "  'support': 496.0},\n",
       " 'label': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0},\n",
       " 'labor issues': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'labour issues': {'precision': 0.1073558648111332,\n",
       "  'recall': 0.2967032967032967,\n",
       "  'f1-score': 0.15766423357664233,\n",
       "  'support': 182.0},\n",
       " 'labour related': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'mergers and acquisitions': {'precision': 0.9173553719008265,\n",
       "  'recall': 0.23870967741935484,\n",
       "  'f1-score': 0.378839590443686,\n",
       "  'support': 465.0},\n",
       " 'no event': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 438.0},\n",
       " 'other': {'precision': 0.17777777777777778,\n",
       "  'recall': 0.010062893081761006,\n",
       "  'f1-score': 0.01904761904761905,\n",
       "  'support': 795.0},\n",
       " 'price targets': {'precision': 0.42857142857142855,\n",
       "  'recall': 0.0030241935483870967,\n",
       "  'f1-score': 0.006006006006006006,\n",
       "  'support': 992.0},\n",
       " 'product approval': {'precision': 0.17647058823529413,\n",
       "  'recall': 0.03333333333333333,\n",
       "  'f1-score': 0.056074766355140186,\n",
       "  'support': 90.0},\n",
       " 'products-services': {'precision': 0.6,\n",
       "  'recall': 0.037209302325581395,\n",
       "  'f1-score': 0.07007299270072993,\n",
       "  'support': 645.0},\n",
       " 'regulatory': {'precision': 0.3677581863979849,\n",
       "  'recall': 0.3310657596371882,\n",
       "  'f1-score': 0.34844868735083534,\n",
       "  'support': 441.0},\n",
       " 'stock price movement': {'precision': 0.5671296296296297,\n",
       "  'recall': 0.21566901408450703,\n",
       "  'f1-score': 0.3125,\n",
       "  'support': 1136.0},\n",
       " 'accuracy': 0.2376237623762376,\n",
       " 'macro avg': {'precision': 0.31658058736651423,\n",
       "  'recall': 0.18917944369609654,\n",
       "  'f1-score': 0.18165075840205017,\n",
       "  'support': 7676.0},\n",
       " 'weighted avg': {'precision': 0.4333708109987506,\n",
       "  'recall': 0.2376237623762376,\n",
       "  'f1-score': 0.2180740502152485,\n",
       "  'support': 7676.0}}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_true=true_labels,\n",
    "    y_pred=responses,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8823c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of your custom model is: lora-tutorial-ns/llama-3.2-1b-xlam-run1@v5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name of your custom model is: {CUSTOMIZED_MODEL}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef763cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
