{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d4c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from nemo_microservices import NeMoMicroservices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dad47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "# Initialize NeMo Microservices SDK client\n",
    "nemo_client = NeMoMicroservices(\n",
    "    base_url=NEMO_URL,\n",
    "    inference_base_url=NIM_URL,\n",
    ")\n",
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfcb4d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 configs\n",
      "Namespace: meta Config:llama-3.2-1b-instruct@v1.0.0+L40 - None\n",
      "Namespace: meta Config:llama-3.2-1b-instruct@v1.0.0+A100 - None\n",
      "Namespace: meta Config:llama-3.1-8b-instruct@v1.0.0+L40 - None\n",
      "Namespace: meta Config:llama-3.1-8b-instruct@v1.0.0+A100 - None\n"
     ]
    }
   ],
   "source": [
    "# List customization configs with filters\n",
    "configs = nemo_client.customization.configs.list(\n",
    "    page=1,\n",
    "    page_size=10,\n",
    "    sort=\"-created_at\",\n",
    "    filter={\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"enabled\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Found {len(configs.data)} configs\")\n",
    "for config in configs.data:\n",
    "    print(f\"Namespace: {config.namespace} Config:{config.name} - {config.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20cc2640-82e4-4530-86d4-ef22836d6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define either here or on config.py\n",
    "BASE_MODEL = \"meta/llama-3.1-8b-instruct\"\n",
    "BASE_MODEL_VERSION = \"v1.0.0+A100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa0be350",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL = 'lora-tutorial-ns/llama-3.1-8b-xlam-run1@v8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "545bba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nemo_client.models.delete(namespace= NMS_NAMESPACE,model_name='llama-3.2-1b-xlam-run1@v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65626934-c54f-4826-a1f4-a5736515d15b",
   "metadata": {},
   "source": [
    "# Override default NeMo Microservices config\n",
    "This allows you to change actual batch size and seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "138b008d-245c-4eed-ac4d-a0c822193a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_NAME = \"llama-3.1-8b-instruct@v1.0.0+A100-new\"  # any unique name in your NS\n",
    "\n",
    "cfg = nemo_client.customization.configs.create(\n",
    "    name=CONFIG_NAME,\n",
    "    namespace=NMS_NAMESPACE,                          \n",
    "    target=\"meta/llama-3.1-8b-instruct@2.0\",                          # e.g., \"meta/llama-3.1-8b-instruct@2.0\"\n",
    "    training_options=[{\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"num_gpus\": 1,\n",
    "        \"micro_batch_size\": 8,                        \n",
    "        \"tensor_parallel_size\": 1,\n",
    "        \"pipeline_parallel_size\": 1,\n",
    "        \"use_sequence_parallel\": False\n",
    "    }],\n",
    "    training_precision=\"bf16-mixed\",\n",
    "    max_seq_length=2048,                               \n",
    "    prompt_template=\"{prompt} {completion}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10099b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created customization job: cust-8t1DsDpsrFYCM9WT7Xn5tL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomizationJob(config='lora-tutorial-ns/llama-3.1-8b-instruct@v1.0.0+A100-better', dataset='lora-tutorial-ns/news-lora-dataset', hyperparameters=Hyperparameters(finetuning_type='lora', batch_size=16, distillation=None, dpo=None, epochs=2, learning_rate=0.0001, log_every_n_steps=None, lora=LoraParameters(adapter_dim=16, adapter_dropout=0.1, alpha=16, target_modules=None), sequence_packing_enabled=True, sft=None, training_type='sft', val_check_interval=None, weight_decay=None), id='cust-8t1DsDpsrFYCM9WT7Xn5tL', config_snapshot=CustomizationConfigJobValue(base_model='meta/llama-3.1-8b-instruct', max_seq_length=2048, precision='bf16-mixed', training_option=CustomizationTrainingOption(finetuning_type='lora', micro_batch_size=4, num_gpus=1, training_type='sft', data_parallel_size=1, num_nodes=1, pipeline_parallel_size=1, tensor_parallel_size=1, use_sequence_parallel=False), dataset_schema=None, prompt_template='{prompt} {completion}'), created_at=datetime.datetime(2025, 8, 29, 20, 23, 7, 877078), dataset_parameters=None, description=None, integrations=None, namespace='default', output_model='lora-tutorial-ns/llama-3.1-8b-xlam-run1@v8', ownership=None, project=None, status='created', status_details=CustomizationStatusDetails(created_at=datetime.datetime(2025, 8, 29, 20, 23, 8, 216817), status=None, updated_at=datetime.datetime(2025, 8, 29, 20, 23, 8, 216817), best_epoch=None, elapsed_time=0.0, epochs_completed=0, metrics=None, percentage_done=0.0, status_logs=[StatusLog(updated_at=datetime.datetime(2025, 8, 29, 20, 23, 8, 216817), detail=None, message='created')], steps_completed=0, steps_per_epoch=None, train_loss=None, val_loss=None), updated_at=datetime.datetime(2025, 8, 29, 20, 23, 7, 877082), warnings=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create customization job\n",
    "# If WANDB_API_KEY is set, we send it in the request header, which will report the training metrics to Weights & Biases (WandB).\n",
    "if WANDB_API_KEY:\n",
    "    client_with_wandb = nemo_client.with_options(default_headers={\"wandb-api-key\": WANDB_API_KEY})\n",
    "else:\n",
    "    client_with_wandb = nemo_client\n",
    "\n",
    "customization = client_with_wandb.customization.jobs.create(\n",
    "    name=\"llama-3.1-8b-xlam-ft-seq-packed\",\n",
    "    output_model=CUSTOM_MODEL,\n",
    "    # config=f\"{BASE_MODEL}@{BASE_MODEL_VERSION}\",\n",
    "    config=f\"{NMS_NAMESPACE}/{CONFIG_NAME}\",\n",
    "    dataset={\"name\": DATASET_NAME, \"namespace\": NMS_NAMESPACE},\n",
    "    # \"max_seq_length\": 4096 -> changing this in hyperparams doesn't do anything needs to be separate\n",
    "    hyperparameters={\n",
    "        \"sequence_packing_enabled\": True,\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"epochs\": 2,\n",
    "        \"batch_size\": 16, # This is actually effectively gradient accumulation\n",
    "        \"learning_rate\": 0.0001,\n",
    "        # \"data_parallel_size\": 1,\n",
    "        \"lora\": {\n",
    "            \"adapter_dim\": 16,\n",
    "            \"adapter_dropout\": 0.1\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Created customization job: {customization.id}\")\n",
    "customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba08fe-623d-45c2-a073-09150c0efc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b99a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To track status\n",
    "JOB_ID = customization.id\n",
    "\n",
    "customization = nemo_client.customization.jobs.retrieve(JOB_ID)\n",
    "\n",
    "# This will be the name of the model that will be used to send inference queries to\n",
    "CUSTOMIZED_MODEL = customization.output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab6c8e2d-4fe1-4035-9a1a-12ccdaef9272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cust-69qSD7RKwtj2TsnHRuH1is'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd388230-b725-40e1-ba78-7ae52f30759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CANCEL = True\n",
    "\n",
    "# if CANCEL:\n",
    "#     nemo_client.customization.jobs.cancel(JOB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8608c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nemo_client.customization.jobs.cancel(job_id=JOB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b012883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage done: 0.0\n",
      "Job Status: {\n",
      "  \"created_at\": \"2025-08-29 19:53:47.429671\",\n",
      "  \"status\": \"pending\",\n",
      "  \"updated_at\": \"2025-08-29 19:53:47.429671\",\n",
      "  \"best_epoch\": null,\n",
      "  \"elapsed_time\": 0.0,\n",
      "  \"epochs_completed\": 0,\n",
      "  \"metrics\": null,\n",
      "  \"percentage_done\": 0.0,\n",
      "  \"status_logs\": [\n",
      "    {\n",
      "      \"updated_at\": \"2025-08-29 19:53:47.429671\",\n",
      "      \"detail\": null,\n",
      "      \"message\": \"created\"\n",
      "    },\n",
      "    {\n",
      "      \"updated_at\": \"2025-08-29 19:53:47.429671\",\n",
      "      \"detail\": \"The training job is pending\",\n",
      "      \"message\": \"TrainingJobPending\"\n",
      "    }\n",
      "  ],\n",
      "  \"steps_completed\": 0,\n",
      "  \"steps_per_epoch\": null,\n",
      "  \"train_loss\": null,\n",
      "  \"val_loss\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    " # Get job status\n",
    "job_status = nemo_client.customization.jobs.status(job_id=JOB_ID)\n",
    "\n",
    "print(\"Percentage done:\", job_status.percentage_done)\n",
    "print(\"Job Status:\", json.dumps(job_status.model_dump(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f2e55ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: running after 30.03 seconds. Progress: 0.0%\n",
      "Job status: running after 60.08 seconds. Progress: 0.0%\n",
      "Job status: running after 90.12 seconds. Progress: 0.0%\n",
      "Job status: running after 120.17 seconds. Progress: 0.0%\n",
      "Job status: running after 150.21 seconds. Progress: 0.0%\n",
      "Job status: running after 180.26 seconds. Progress: 0.0%\n",
      "Job status: running after 210.31 seconds. Progress: 0.0%\n",
      "Job status: running after 240.35 seconds. Progress: 0.0%\n",
      "Job status: running after 270.40 seconds. Progress: 0.0%\n",
      "Job status: running after 300.44 seconds. Progress: 0.0%\n",
      "Job status: running after 330.48 seconds. Progress: 0.0%\n",
      "Job status: running after 360.53 seconds. Progress: 0.0%\n",
      "Job status: running after 390.58 seconds. Progress: 0.0%\n",
      "Job status: running after 420.61 seconds. Progress: 0.0%\n",
      "Job status: running after 450.65 seconds. Progress: 0.0%\n",
      "Job status: running after 480.70 seconds. Progress: 0.0%\n",
      "Job status: running after 510.75 seconds. Progress: 0.0%\n",
      "Job status: running after 540.79 seconds. Progress: 0.0%\n",
      "Job status: running after 570.82 seconds. Progress: 0.0%\n",
      "Job status: running after 600.84 seconds. Progress: 0.0%\n",
      "Job status: running after 630.88 seconds. Progress: 0.0%\n",
      "Job status: running after 660.90 seconds. Progress: 0.0%\n",
      "Job status: running after 690.99 seconds. Progress: 0.0%\n",
      "Job status: running after 721.03 seconds. Progress: 0.0%\n",
      "Job status: running after 751.33 seconds. Progress: 0.0%\n",
      "Job status: running after 781.36 seconds. Progress: 0.0%\n"
     ]
    },
    {
     "ename": "APITimeoutError",
     "evalue": "Request timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect_failed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36m_connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"connect_tcp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_tcp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                         \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mconnect_tcp\u001b[0;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             sock = socket.create_connection(\n",
      "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_exceptions.py\u001b[0m in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_exc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mto_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mraise\u001b[0m  \u001b[0;31m# pragma: nocover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/nemo_microservices/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m    993\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mmapped_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPITimeoutError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_281680/2228711322.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnemo_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJOB_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolling_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Wait for 2 minutes, because sometimes, the job is finished, but the finetuned model is not ready in NIM yet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_281680/2228711322.py\u001b[0m in \u001b[0;36mwait_job\u001b[0;34m(nemo_client, job_id, polling_interval, timeout)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m        \u001b[0;31m# Fetch updated status and progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m        \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnemo_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m        \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m        \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/nemo_microservices/resources/customization/jobs.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self, job_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected a non-empty value for `job_id` but received {job_id!r}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         return self._get(\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;34mf\"/v1/customization/jobs/{job_id}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             options=make_request_options(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/nemo_microservices/_base_client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, path, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# cast is required because mypy complains about returning Any even though\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;31m# it understands the type variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/nemo_microservices/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raising timeout error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAPITimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Encountered Exception\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAPITimeoutError\u001b[0m: Request timed out."
     ]
    }
   ],
   "source": [
    " # Add wait job function to wait for the customization job to complete\n",
    "\n",
    "from time import sleep, time\n",
    "\n",
    "def wait_job(nemo_client, job_id: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    \"\"\"Helper for waiting an eval job using SDK.\"\"\"\n",
    "    start_time = time()\n",
    "    job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "    status = job.status\n",
    "\n",
    "    while (status in [\"pending\", \"created\", \"running\"]):\n",
    "        # Check for timeout\n",
    "        if time() - start_time > timeout:\n",
    "            raise RuntimeError(f\"Took more than {timeout} seconds.\")\n",
    "\n",
    "        # Sleep before polling again\n",
    "        sleep(polling_interval)\n",
    "\n",
    "        # Fetch updated status and progress\n",
    "        job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "        status = job.status\n",
    "        progress = 0.0\n",
    "        if status == \"running\" and job.status_details:\n",
    "            progress = job.status_details.percentage_done or 0.0\n",
    "        elif status == \"completed\":\n",
    "            progress = 100\n",
    "\n",
    "        print(f\"Job status: {status} after {time() - start_time:.2f} seconds. Progress: {progress}%\")\n",
    "\n",
    "\n",
    "    return job\n",
    "\n",
    "job = wait_job(nemo_client, JOB_ID, polling_interval=30, timeout=24000)\n",
    "\n",
    "# Wait for 2 minutes, because sometimes, the job is finished, but the finetuned model is not ready in NIM yet.\n",
    "sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "829fec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 models in namespace lora-tutorial-ns:\n",
      "\n",
      "Model: llama-3.2-1b-xlam-run1@v5\n",
      "  Namespace: lora-tutorial-ns\n",
      "  Base Model: meta/llama-3.2-1b-instruct\n",
      "  Created: 2025-08-13 18:17:19.448554\n",
      "  Fine-tuning Type: lora\n",
      "\n",
      "Model: llama-3.2-1b-xlam-run1@v4\n",
      "  Namespace: lora-tutorial-ns\n",
      "  Base Model: meta/llama-3.2-1b-instruct\n",
      "  Created: 2025-08-13 17:02:36.340413\n",
      "  Fine-tuning Type: lora\n",
      "\n",
      "Model: llama-3.2-1b-xlam-run1@v1\n",
      "  Namespace: lora-tutorial-ns\n",
      "  Base Model: meta/llama-3.2-1b-instruct\n",
      "  Created: 2025-08-13 14:33:29.640105\n",
      "  Fine-tuning Type: lora\n"
     ]
    }
   ],
   "source": [
    " # List models with filters\n",
    "models_page = nemo_client.models.list(\n",
    "    filter={\"namespace\": NMS_NAMESPACE},\n",
    "    sort=\"-created_at\"\n",
    ")\n",
    "\n",
    "# Print models information\n",
    "print(f\"Found {len(models_page.data)} models in namespace {NMS_NAMESPACE}:\")\n",
    "for model in models_page.data:\n",
    "    print(f\"\\nModel: {model.name}\")\n",
    "    print(f\"  Namespace: {model.namespace}\")\n",
    "    print(f\"  Base Model: {model.base_model}\")\n",
    "    print(f\"  Created: {model.created_at}\")\n",
    "    if model.peft:\n",
    "        print(f\"  Fine-tuning Type: {model.peft.finetuning_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b6f8f779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: lora-tutorial-ns/llama-3.2-1b-xlam-run1@v5\n",
      "Base Model: meta/llama-3.2-1b-instruct\n",
      "Status: upload_completed\n"
     ]
    }
   ],
   "source": [
    "# CUSTOMIZED_MODEL is constructed as `namespace/model_name`, so we need to extract the model name\n",
    "model = nemo_client.models.retrieve(namespace=NMS_NAMESPACE, model_name=CUSTOMIZED_MODEL.split(\"/\")[1])\n",
    "\n",
    "print(f\"Model: {model.namespace}/{model.name}\")\n",
    "print(f\"Base Model: {model.base_model}\")\n",
    "print(f\"Status: {model.artifact.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "32ac0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Check if the custom LoRA model is hosted by NVIDIA NIM\n",
    "models = nemo_client.inference.models.list()\n",
    "model_names = [model.id for model in models.data]\n",
    "\n",
    "assert CUSTOMIZED_MODEL in model_names, \\\n",
    "    f\"Model {CUSTOMIZED_MODEL} not found\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "693b9b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7676 examples in the test set\n"
     ]
    }
   ],
   "source": [
    "def read_jsonl(file_path):\n",
    "    \"\"\"Reads a JSON Lines file and yields parsed JSON objects\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "test_data = list(read_jsonl(test_fp))\n",
    "\n",
    "print(f\"There are {len(test_data)} examples in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a1fbc147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 77 batches\n",
      "First batch has 100 messages\n",
      "Sample message from first batch: {'role': 'user', 'content': \"Given the following headline:\\n### START HEADLINE ###\\n\\nHearing Endo Int'l Held Talks to Sell Paladin Labs to Knight Therapeutics\\n\\n### END HEADLINE ###\\n\\nWhat event type best classifies it? Choose from the following list:\\n\\n-analyst rating\\n-price targets\\n-earnings\\n-labour related\\n-mergers and acquisitions\\n-dividends\\n-regulatory\\n-stock price movement\\n-credit ratings\\n-products-services\\n-product approval\\n-guidance\\n-other\\n\\nProvide only the event type putting it inside double square brackets and in a new line like:\\n[[label]]\\n\\n### START EVENT OUTPUT ###\\n\\n\"}\n"
     ]
    }
   ],
   "source": [
    "def create_message_batches(data_list, batch_size=100):\n",
    "    \"\"\"\n",
    "    Creates batches of messages from a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        data_list: List of dictionaries containing 'prompt' key\n",
    "        batch_size: Size of each batch (default: 100)\n",
    "    \n",
    "    Returns:\n",
    "        List of batches, where each batch contains message dictionaries\n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    \n",
    "    for i in range(0, len(data_list), batch_size):\n",
    "        batch = data_list[i:i + batch_size]\n",
    "        \n",
    "        # Create messages for this batch\n",
    "        batch_messages = []\n",
    "        for test_sample in batch:\n",
    "            messages = {\"role\": \"user\", \"content\": test_sample['prompt']}\n",
    "            batch_messages.append(messages)\n",
    "        \n",
    "        batches.append(batch_messages)\n",
    "    \n",
    "    return batches\n",
    "\n",
    "# Usage example:\n",
    "message_batches = create_message_batches(test_data, batch_size=100)\n",
    "\n",
    "print(f\"Created {len(message_batches)} batches\")\n",
    "print(f\"First batch has {len(message_batches[0])} messages\")\n",
    "print(f\"Sample message from first batch: {message_batches[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d523f724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 messages\n",
      "Processed 1000 messages\n",
      "Processed 1500 messages\n",
      "Processed 2000 messages\n",
      "Processed 2500 messages\n",
      "Processed 3000 messages\n",
      "Processed 3500 messages\n",
      "Processed 4000 messages\n",
      "Processed 4500 messages\n",
      "Processed 5000 messages\n",
      "Processed 5500 messages\n",
      "Processed 6000 messages\n",
      "Processed 6500 messages\n",
      "Processed 7000 messages\n",
      "Processed 7500 messages\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "c=0\n",
    "for batch in message_batches:\n",
    "    for message in batch:\n",
    "        completion = nemo_client.chat.completions.create(model = CUSTOMIZED_MODEL,\n",
    "                                            messages = [message],\n",
    "                                            temperature = 0.1,\n",
    "                                            top_p = 0.7,\n",
    "                                            max_tokens = 512,\n",
    "                                            stream = False\n",
    "                                            )\n",
    "        resp = completion.choices[0].message.content\n",
    "        responses.append(resp)\n",
    "        c += 1\n",
    "        if c % 500 == 0:\n",
    "            print(f\"Processed {c} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "71268686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean responses using lambda to remove square brackets\n",
    "responses = list(map(lambda x: x.replace('[', '').replace(']', '').replace('-p','p').replace('-e','e'), responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4c80b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = list(map(lambda x: x.lower(), responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2ccfa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [i['completion'] for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "da742a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyst rating',\n",
       " 'credit ratings',\n",
       " 'dividends',\n",
       " 'earnings',\n",
       " 'guidance',\n",
       " 'labour issues',\n",
       " 'mergers and acquisitions',\n",
       " 'no event',\n",
       " 'other',\n",
       " 'price targets',\n",
       " 'product approval',\n",
       " 'products-services',\n",
       " 'regulatory',\n",
       " 'stock price movement'}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a5c25844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyst rating',\n",
       " 'credit ratings',\n",
       " 'dividends',\n",
       " 'dividers',\n",
       " 'earnings',\n",
       " 'growth',\n",
       " 'guidance',\n",
       " 'label',\n",
       " 'labor issues',\n",
       " 'labour issues',\n",
       " 'labour related',\n",
       " 'mergers and acquisitions',\n",
       " 'other',\n",
       " 'price targets',\n",
       " 'product approval',\n",
       " 'products-services',\n",
       " 'regulatory',\n",
       " 'stock price movement'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ece775d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3f769509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyst rating': {'precision': 0.1497019715726731,\n",
       "  'recall': 0.7709563164108618,\n",
       "  'f1-score': 0.250719907851795,\n",
       "  'support': 847.0},\n",
       " 'credit ratings': {'precision': 0.6363636363636364,\n",
       "  'recall': 0.175,\n",
       "  'f1-score': 0.27450980392156865,\n",
       "  'support': 40.0},\n",
       " 'dividends': {'precision': 0.9591836734693877,\n",
       "  'recall': 0.8623853211009175,\n",
       "  'f1-score': 0.9082125603864735,\n",
       "  'support': 109.0},\n",
       " 'dividers': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'earnings': {'precision': 0.7695852534562212,\n",
       "  'recall': 0.334,\n",
       "  'f1-score': 0.46582984658298465,\n",
       "  'support': 1000.0},\n",
       " 'growth': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0},\n",
       " 'guidance': {'precision': 0.15777777777777777,\n",
       "  'recall': 0.2862903225806452,\n",
       "  'f1-score': 0.2034383954154728,\n",
       "  'support': 496.0},\n",
       " 'label': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0},\n",
       " 'labor issues': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'labour issues': {'precision': 0.1073558648111332,\n",
       "  'recall': 0.2967032967032967,\n",
       "  'f1-score': 0.15766423357664233,\n",
       "  'support': 182.0},\n",
       " 'labour related': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " 'mergers and acquisitions': {'precision': 0.9173553719008265,\n",
       "  'recall': 0.23870967741935484,\n",
       "  'f1-score': 0.378839590443686,\n",
       "  'support': 465.0},\n",
       " 'no event': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 438.0},\n",
       " 'other': {'precision': 0.17777777777777778,\n",
       "  'recall': 0.010062893081761006,\n",
       "  'f1-score': 0.01904761904761905,\n",
       "  'support': 795.0},\n",
       " 'price targets': {'precision': 0.42857142857142855,\n",
       "  'recall': 0.0030241935483870967,\n",
       "  'f1-score': 0.006006006006006006,\n",
       "  'support': 992.0},\n",
       " 'product approval': {'precision': 0.17647058823529413,\n",
       "  'recall': 0.03333333333333333,\n",
       "  'f1-score': 0.056074766355140186,\n",
       "  'support': 90.0},\n",
       " 'products-services': {'precision': 0.6,\n",
       "  'recall': 0.037209302325581395,\n",
       "  'f1-score': 0.07007299270072993,\n",
       "  'support': 645.0},\n",
       " 'regulatory': {'precision': 0.3677581863979849,\n",
       "  'recall': 0.3310657596371882,\n",
       "  'f1-score': 0.34844868735083534,\n",
       "  'support': 441.0},\n",
       " 'stock price movement': {'precision': 0.5671296296296297,\n",
       "  'recall': 0.21566901408450703,\n",
       "  'f1-score': 0.3125,\n",
       "  'support': 1136.0},\n",
       " 'accuracy': 0.2376237623762376,\n",
       " 'macro avg': {'precision': 0.31658058736651423,\n",
       "  'recall': 0.18917944369609654,\n",
       "  'f1-score': 0.18165075840205017,\n",
       "  'support': 7676.0},\n",
       " 'weighted avg': {'precision': 0.4333708109987506,\n",
       "  'recall': 0.2376237623762376,\n",
       "  'f1-score': 0.2180740502152485,\n",
       "  'support': 7676.0}}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_true=true_labels,\n",
    "    y_pred=responses,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8823c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of your custom model is: lora-tutorial-ns/llama-3.2-1b-xlam-run1@v5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name of your custom model is: {CUSTOMIZED_MODEL}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef763cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
